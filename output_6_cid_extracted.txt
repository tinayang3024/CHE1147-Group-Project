=== Loading cleaned dataset ===
[IO] loaded DataFrame ← /Users/yang/Documents/grad/che1147/CHE1147-Group-Project/data/processed/enzyme_clean.parquet shape=(162856, 371)
[Feature prep] X shape=(162856, 332), targets=['kcat_value', 'km_value']

=== Tuning & Training: kcat_value ===
[kcat_value] Running parameter search...
Fitting 3 folds for each of 15 candidates, totalling 45 fits
[kcat_value] Best params: {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 500, 'reg_lambda': 0.10994335574766201, 'subsample': 0.7}

[kcat_value] Tuned Model (log space):
MAE: 0.9478 | RMSE: 1.2899 | R²: 0.4206
[Saved model] → models/xgb_kcat_value_tuned.joblib

=== Tuning & Training: km_value ===
[km_value] Running parameter search...
Fitting 3 folds for each of 15 candidates, totalling 45 fits
[km_value] Best params: {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 500, 'reg_lambda': 0.10994335574766201, 'subsample': 0.7}

[km_value] Tuned Model (log space):
MAE: 0.7691 | RMSE: 1.0432 | R²: 0.5046
[Saved model] → models/xgb_km_value_tuned.joblib

=== Training Summary (log space) ===
kcat_value: MAE=0.9478, RMSE=1.2899, R²=0.4206
  → Best Params: {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 500, 'reg_lambda': 0.10994335574766201, 'subsample': 0.7}
km_value: MAE=0.7691, RMSE=1.0432, R²=0.5046
  → Best Params: {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 500, 'reg_lambda': 0.10994335574766201, 'subsample': 0.7}
